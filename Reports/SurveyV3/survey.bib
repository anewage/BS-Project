
@inproceedings{liu_detecting_2017,
	address = {Republic and Canton of Geneva, Switzerland},
	series = {{WWW} '17},
	title = {Detecting {Collusive} {Spamming} {Activities} in {Community} {Question} {Answering}},
	isbn = {978-1-4503-4913-0},
	url = {https://doi.org/10.1145/3038912.3052594},
	doi = {10.1145/3038912.3052594},
	abstract = {Community Question Answering (CQA) portals provide rich sources of information on a variety of topics. However, the authenticity and quality of questions and answers (Q\&As) has proven hard to control. In a troubling direction, the widespread growth of crowdsourcing websites has created a large-scale, potentially difficult-to-detect workforce to manipulate malicious contents in CQA. The crowd workers who join the same crowdsourcing task about promotion campaigns in CQA collusively manipulate deceptive Q\&As for promoting a target (product or service). The collusive spamming group can fully control the sentiment of the target. How to utilize the structure and the attributes for detecting manipulated Q\&As? How to detect the collusive group and leverage the group information for the detection task? To shed light on these research questions, we propose a unified framework to tackle the challenge of detecting collusive spamming activities of CQA. First, we interpret the questions and answers in CQA as two independent networks. Second, we detect collusive question groups and answer groups from these two networks respectively by measuring the similarity of the contents posted within a short duration. Third, using attributes (individual-level and group-level) and correlations (user-based and content-based), we proposed a combined factor graph model to detect deceptive Q\&As simultaneously by combining two independent factor graphs. With a large-scale practical data set, we find that the proposed framework can detect deceptive contents at early stage, and outperforms a number of competitive baselines.},
	urldate = {2018-02-25},
	booktitle = {Proceedings of the 26th {International} {Conference} on {World} {Wide} {Web}},
	publisher = {International World Wide Web Conferences Steering Committee},
	author = {Liu, Yuli and Liu, Yiqun and Zhou, Ke and Zhang, Min and Ma, Shaoping},
	year = {2017},
	keywords = {community question answering, crowdsourcing manipulation, factor graph., spam detection},
	pages = {1073--1082}
}

@book{pressman_software_2015,
	address = {New York, NY},
	edition = {Eighth edition},
	title = {Software engineering: a practitioner's approach},
	isbn = {978-0-07-802212-8},
	shorttitle = {Software engineering},
	publisher = {McGraw-Hill Education},
	author = {Pressman, Roger S.},
	year = {2015},
	keywords = {Software engineering},
	file = {Software_Engineering_A_Practitioner’s.pdf:D\:\\Documents\\Courses\\Software Engineering\\Software_Engineering_A_Practitioner’s.pdf:application/pdf}
}

@book{sommerville_software_2016,
	address = {Boston, Mass. Amsterdam Cape Town},
	edition = {Tenth edition, global edition},
	series = {Always learning},
	title = {Software engineering},
	isbn = {978-1-292-09613-1},
	language = {eng},
	publisher = {Pearson Education Limited},
	author = {Sommerville, Ian},
	year = {2016},
	note = {OCLC: 934508916},
	annote = {Hier auch später erschienene, unveränderte Nachdrucke},
	file = {Ian Sommerville-Software Engineering-Pearson (2015).pdf:D\:\\Documents\\Courses\\Software Engineering\\Ian Sommerville-Software Engineering-Pearson (2015).pdf:application/pdf}
}

@misc{noauthor_amazon_nodate,
	title = {Amazon {Mechanical} {Turk}},
	url = {https://www.mturk.com/},
	urldate = {2018-03-03}
}

@misc{noauthor_training_nodate,
	title = {Training data, machine learning and human-in-the-loop for {A}.{I}.},
	url = {https://www.crowdflower.com/},
	abstract = {Training data, machine learning, and human-in-the-loop for (AI) artificial intelligence in a single, essential platform for data science teams.},
	language = {en-US},
	urldate = {2018-03-03},
	journal = {CrowdFlower},
	file = {Snapshot:C\:\\Users\\Amir\\Zotero\\storage\\NEPXYIP9\\www.crowdflower.com.html:text/html}
}

@article{liu_cdas:_2012,
	title = {{CDAS}: {A} {Crowdsourcing} {Data} {Analytics} {System}},
	shorttitle = {{CDAS}},
	url = {http://arxiv.org/abs/1207.0143},
	abstract = {Some complex problems, such as image tagging and natural language processing, are very challenging for computers, where even state-of-the-art technology is yet able to provide satisfactory accuracy. Therefore, rather than relying solely on developing new and better algorithms to handle such tasks, we look to the crowdsourcing solution -- employing human participation -- to make good the shortfall in current technology. Crowdsourcing is a good supplement to many computer tasks. A complex job may be divided into computer-oriented tasks and human-oriented tasks, which are then assigned to machines and humans respectively. To leverage the power of crowdsourcing, we design and implement a Crowdsourcing Data Analytics System, CDAS. CDAS is a framework designed to support the deployment of various crowdsourcing applications. The core part of CDAS is a quality-sensitive answering model, which guides the crowdsourcing engine to process and monitor the human tasks. In this paper, we introduce the principles of our quality-sensitive model. To satisfy user required accuracy, the model guides the crowdsourcing query engine for the design and processing of the corresponding crowdsourcing jobs. It provides an estimated accuracy for each generated result based on the human workers' historical performances. When verifying the quality of the result, the model employs an online strategy to reduce waiting time. To show the effectiveness of the model, we implement and deploy two analytics jobs on CDAS, a twitter sentiment analytics job and an image tagging job. We use real Twitter and Flickr data as our queries respectively. We compare our approaches with state-of-the-art classification and image annotation techniques. The results show that the human-assisted methods can indeed achieve a much higher accuracy. By embedding the quality-sensitive model into crowdsourcing query engine, we effectiv...[truncated].},
	urldate = {2018-03-03},
	journal = {arXiv:1207.0143 [cs]},
	author = {Liu, Xuan and Lu, Meiyu and Ooi, Beng Chin and Shen, Yanyan and Wu, Sai and Zhang, Meihui},
	month = jun,
	year = {2012},
	note = {arXiv: 1207.0143},
	keywords = {Computer Science - Databases},
	annote = {Comment: VLDB2012},
	file = {arXiv\:1207.0143 PDF:C\:\\Users\\Amir\\Zotero\\storage\\25AF3664\\Liu et al. - 2012 - CDAS A Crowdsourcing Data Analytics System.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Amir\\Zotero\\storage\\3KUP64EU\\1207.html:text/html}
}

@inproceedings{guo_so_2012,
	address = {New York, NY, USA},
	series = {{SIGMOD} '12},
	title = {So {Who} {Won}?: {Dynamic} {Max} {Discovery} with the {Crowd}},
	isbn = {978-1-4503-1247-9},
	shorttitle = {So {Who} {Won}?},
	url = {http://doi.acm.org/10.1145/2213836.2213880},
	doi = {10.1145/2213836.2213880},
	abstract = {We consider a crowdsourcing database system that may cleanse, populate, or filter its data by using human workers. Just like a conventional DB system, such a crowdsourcing DB system requires data manipulation functions such as select, aggregate, maximum, average, and so on, except that now it must rely on human operators (that for example compare two objects) with very different latency, cost and accuracy characteristics. In this paper, we focus on one such function, maximum, that finds the highest ranked object or tuple in a set. In particularm we study two problems: given a set of votes (pairwise comparisons among objects), how do we select the maximum? And how do we improve our estimate by requesting additional votes? We show that in a crowdsourcing DB system, the optimal solution to both problems is NP-Hard. We then provide heuristic functions to select the maximum given evidence, and to select additional votes. We experimentally evaluate our functions to highlight their strengths and weaknesses.},
	urldate = {2018-03-03},
	booktitle = {Proceedings of the 2012 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Guo, Stephen and Parameswaran, Aditya and Garcia-Molina, Hector},
	year = {2012},
	keywords = {aggregation, crowdsourcing, human computation, max, voting},
	pages = {385--396}
}

@book{___1389,
	address = {تهران},
	edition = {اول},
	title = {کلیات متدولوژی تامین کیفیت},
	language = {Persian},
	publisher = {نشر آدینه},
	author = {عبداله‌زاده بارفروش, احمد},
	year = {1389}
}

@book{krug_dont_2018,
	title = {Don't make me think!: {Web} \& {Mobile} {Usability}: {Das} intuitive {Web}},
	isbn = {978-3-95845-766-9},
	shorttitle = {Don't make me think!},
	abstract = {Wie User tatsächlich mit Websites umgehen Verblüffend einfache Website-StrategienLayout und Navigation benutzerfreundlich gestalten Usability ist eine der wichtigsten Herausforderungen bei der Webseitenerstellung – und wird häufig nur allzu leichtfertig vernachlässigt. Lernen Sie mit dieser überarbeiteten Neuauflage des Klassikers, wie Websites wirklich benutzt werden – mit aktualisierten Beispielen und einem neuen Kapitel über Mobile Usability. Steve Krug verdankt seine Erkenntnisse einer eigentlich nahe liegenden Methode: Er beobachtet, wie User mit einer Website umgehen und welche Hindernisse sich ihnen bei der Informationssuche in den Weg stellen. Anhand aussagekräftiger Beispiele, vieler Grafiken und einer Prise Humor erhalten Sie eine ganz neue Perspektive auf Ihr Websitekonzept. Krugs Usability-Prinzipien dienen als Leitfaden für die eigene Arbeit. Mit einfachen Tests kann jeder seine Website ohne viel Aufwand so optimieren, dass sie den Usability-Kriterien entspricht und sich intuitiv anwenden lässt. Wenn Sie diesen Klassiker schon einmal gelesen haben, werden Sie wieder entdecken, was DON’T MAKE ME THINK! so unverzichtbar für Webdesigner und -entwickler auf der ganzen Welt gemacht hat. Wenn Sie es noch nicht gelesen haben, werden Sie sehen, warum so viele Leute es als Pflichtlektüre empfehlen.  Aus dem Inhalt: • Krugs erstes Gesetz der Usability• Wie wir das Web wirklich nutzen• Konventionen einsetzen• Effektive visuelle Hierarchien erzeugen• Die Webseite in klar definierte Bereiche teilen• Keinen Zweifel darüber lassen, was anklickbar ist• Inhalte für die bessere Lesbarkeit formatieren• Das Design der Navigation• Konventionen der Webnavigation• Aussehen und Hierarchie der Startseite• Usability-Tests effektiv gestalten• Mobile Webseiten• Barrierefreiheit},
	language = {de},
	publisher = {MITP-Verlags GmbH \& Co. KG},
	author = {Krug, Steve},
	month = jan,
	year = {2018},
	keywords = {Computers / General, Computers / Social Aspects / Human-Computer Interaction, Computers / Web / Design, Computers / Web / General}
}

@book{krug_dont_2000,
	edition = {1},
	title = {Don't make me think!: a common sense approach to {Web} usability},
	publisher = {Pearson Education India},
	author = {Krug, Steve},
	year = {2000}
}

@article{p._miguel_review_2014,
	title = {A {Review} of {Software} {Quality} {Models} for the {Evaluation} of {Software} {Products}},
	volume = {5},
	issn = {09762221, 09759018},
	url = {http://airccse.org/journal/ijsea/papers/5614ijsea03.pdf},
	doi = {10.5121/ijsea.2014.5603},
	abstract = {Actually, software products are increasing in a fast way and are used in almost all activities of human life. Consequently measuring and evaluating the quality of a software product has become a critical task for many companies. Several models have been proposed to help diverse types of users with quality issues. The development of techniques for building software has influenced the creation of models to assess the quality. Since 2000 the construction of software started to depend on generated or manufactured components and gave rise to new challenges for assessing quality. These components introduce new concepts such as configurability, reusability, availability, better quality and lower cost. Consequently the models are classified in basic models which were developed until 2000, and those based on components called tailored quality models. The purpose of this article is to describe the main models with their strengths and point out some deficiencies. In this work, we conclude that in the present age, aspects of communications play an important factor in the quality of software.},
	language = {en},
	number = {6},
	urldate = {2018-04-21},
	journal = {International Journal of Software Engineering \& Applications},
	author = {P. Miguel, José and Mauricio, David and Rodríguez, Glen},
	month = nov,
	year = {2014},
	pages = {31--53},
	file = {P. Miguel et al. - 2014 - A Review of Software Quality Models for the Evalua.pdf:C\:\\Users\\Amir\\Zotero\\storage\\7LDHTCAB\\P. Miguel et al. - 2014 - A Review of Software Quality Models for the Evalua.pdf:application/pdf}
}

@article{bastien_usability_2010,
	title = {Usability testing: a review of some methodological and technical aspects of the method},
	volume = {79},
	issn = {13865056},
	shorttitle = {Usability testing},
	url = {http://linkinghub.elsevier.com/retrieve/pii/S1386505608002098},
	doi = {10.1016/j.ijmedinf.2008.12.004},
	abstract = {The aim of this paper is to review some work conducted in the ﬁeld of user testing that aims at specifying or clarifying the test procedures and at deﬁning and developing tools to help conduct user tests. The topics that have been selected were considered relevant for evaluating applications in the ﬁeld of medical and health care informatics. These topics are: the number of participants that should take part in a user test, the test procedure, remote usability evaluation, usability testing tools, and evaluating mobile applications.},
	language = {en},
	number = {4},
	urldate = {2018-06-27},
	journal = {International Journal of Medical Informatics},
	author = {Bastien, J.M. Christian},
	month = apr,
	year = {2010},
	pages = {e18--e23},
	file = {Bastien - 2010 - Usability testing a review of some methodological.pdf:C\:\\Users\\Amir\\Zotero\\storage\\MPZAFAP2\\Bastien - 2010 - Usability testing a review of some methodological.pdf:application/pdf}
}

@misc{noauthor_cmmi_nodate,
	title = {{CMMI} {Institute} - {Capability} {Maturity} {Model} {Integration}},
	url = {https://cmmiinstitute.com/cmmi},
	urldate = {2018-06-28},
	file = {CMMI Institute - Capability Maturity Model Integration:C\:\\Users\\Amir\\Zotero\\storage\\IY9HVXQC\\cmmi.html:text/html}
}

@misc{noauthor_computing_nodate,
	title = {Computing {Research} \& {Education}},
	url = {http://www.core.edu.au/},
	urldate = {2018-07-08},
	file = {Computing Research & Education:C\:\\Users\\Amir\\Zotero\\storage\\AFHBPPWI\\www.core.edu.au.html:text/html}
}

@misc{noauthor_dblp:_nodate,
	title = {dblp: computer science bibliography},
	url = {https://dblp.uni-trier.de/},
	urldate = {2018-07-08}
}

@misc{noauthor_scimago_nodate,
	title = {Scimago {Journal} \& {Country} {Rank}},
	url = {https://www.scimagojr.com/},
	urldate = {2018-07-08},
	file = {Scimago Journal & Country Rank:C\:\\Users\\Amir\\Zotero\\storage\\CHL75QPR\\www.scimagojr.com.html:text/html}
}

@article{seffah_usability_2006,
	title = {Usability measurement and metrics: {A} consolidated model},
	volume = {14},
	issn = {0963-9314, 1573-1367},
	shorttitle = {Usability measurement and metrics},
	url = {https://link.springer.com/article/10.1007/s11219-006-7600-8},
	doi = {10.1007/s11219-006-7600-8},
	abstract = {Usability is increasingly recognized as an important quality factor for interactive software systems, including traditional GUIs-style applications, Web sites, and the large variety of mobile and PDA interactive services. Unusable user interfaces are probably the single largest reasons why encompassing interactive systems – computers plus people, fail in actual use. The design of this diversity of applications so that they actually achieve their intended purposes in term of ease of use is not an easy task. Although there are many individual methods for evaluating usability; they are not well integrated into a single conceptual framework that facilitate their usage by developers who are not trained in the filed of HCI. This is true in part because there are now several different standards (e.g., ISO 9241, ISO/IEC 9126, IEEE Std.610.12) or conceptual models (e.g., Metrics for Usability Standards in Computing [MUSiC]) for usability, and not all of these standards or models describe the same operational definitions and measures. This paper first reviews existing usability standards and models while highlighted the limitations and complementarities of the various standards. It then explains how these various models can be unified into a single consolidated, hierarchical model of usability measurement. This consolidated model is called Quality in Use Integrated Measurement (QUIM). Included in the QUIM model are 10 factors each of which corresponds to a specific facet of usability that is identified in an existing standard or model. These 10 factors are decomposed into a total of 26 sub-factors or measurable criteria that are furtherdecomposed into 127 specific metrics. The paper explains also how a consolidated model, such as QUIM, can help in developing a usability measurement theory.},
	language = {en},
	number = {2},
	urldate = {2018-07-08},
	journal = {Software Quality Journal},
	author = {Seffah, Ahmed and Donyaee, Mohammad and Kline, Rex B. and Padda, Harkirat K.},
	month = jun,
	year = {2006},
	pages = {159--178},
	file = {Snapshot:C\:\\Users\\Amir\\Zotero\\storage\\JV5SQBCT\\s11219-006-7600-8.html:text/html}
}

@book{albert_measuring_2013,
	edition = {2},
	title = {Measuring the {User} {Experience}: {Collecting}, {Analyzing}, and {Presenting} {Usability} {Metrics}},
	isbn = {978-0-08-055826-4},
	shorttitle = {Measuring the {User} {Experience}},
	abstract = {Measuring the User Experience provides the first single source of practical information to enable usability professionals and product developers to effectively measure the usability of any product by choosing the right metric, applying it, and effectively using the information it reveals. Authors Tullis and Albert organize dozens of metrics into six categories: performance, issues-based, self-reported, web navigation, derived, and behavioral/physiological. They explore each metric, considering best methods for collecting, analyzing, and presenting the data. They provide step-by-step guidance for measuring the usability of any type of product using any type of technology. This book is recommended for usability professionals, developers, programmers, information architects, interaction designers, market researchers, and students in an HCI or HFE program.• Presents criteria for selecting the most appropriate metric for every case• Takes a product and technology neutral approach • Presents in-depth case studies to show how organizations have successfully used the metrics and the information they revealed},
	language = {en},
	publisher = {Elsevier: Morgan Kaufmann},
	author = {Albert, William and Tullis, Thomas},
	month = jul,
	year = {2013},
	keywords = {Computers / Operating Systems / General, Computers / User Interfaces}
}

@article{agarwal_assessing_2002,
	title = {Assessing a {Firm}'s {Web} {Presence}: {A} {Heuristic} {Evaluation} {Procedure} for the {Measurement} of {Usability}},
	volume = {13},
	issn = {1047-7047, 1526-5536},
	shorttitle = {Assessing a {Firm}'s {Web} {Presence}},
	url = {http://pubsonline.informs.org/doi/abs/10.1287/isre.13.2.168.84},
	doi = {10.1287/isre.13.2.168.84},
	language = {en},
	number = {2},
	urldate = {2018-07-08},
	journal = {Information Systems Research},
	author = {Agarwal, Ritu and Venkatesh, Viswanath},
	month = jun,
	year = {2002},
	pages = {168--186},
	file = {Agarwal and Venkatesh - 2002 - Assessing a Firm's Web Presence A Heuristic Evalu.pdf:C\:\\Users\\Amir\\Zotero\\storage\\RQKT5RTL\\Agarwal and Venkatesh - 2002 - Assessing a Firm's Web Presence A Heuristic Evalu.pdf:application/pdf}
}

@misc{noauthor_bluffton_2018,
	title = {Bluffton {University} bus crash},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Bluffton_University_bus_crash&oldid=843580777},
	abstract = {The Bluffton University bus crash was an automobile crash that occurred during the early morning hours of March 2, 2007, on Interstate 75 in Atlanta, Georgia. A chartered motorcoach was carrying 33 members of the Bluffton University baseball team from Bluffton, Ohio, on their way to a tournament game during spring break in Sarasota, Florida. The group planned to travel without an overnight stop on the approximately 900-mile, 18-hour trip. The trip went without incident from Bluffton south to a motel in Adairsville, Georgia, at which time a relief driver began operating the bus for the second half of the trip.
About 5:38 am EST, while operating the motorcoach southbound in a left-hand HOV lane of I-75 in the Atlanta metropolitan area, the driver accidentally entered a left exit ramp, which ended abruptly at an elevated T-junction marked by a stop sign. When it reached the top of the ramp and the stop sign, the bus was traveling at highway speed. The driver lost control of the bus, which slid sideways into a concrete bridge wall and chain-link security fence, then fell 19 feet, landing on its left side across the interstate highway below. Twenty-nine passengers survived the crash, while seven occupants were killed.
The U.S. National Transportation Safety Board (NTSB) dispatched a team to the scene and began an investigation. Local and state police and officials of the Georgia Department of Transportation (GDOT) also investigated. In its final report, the NTSB determined that the probable cause was "the motorcoach driver's mistaking the HOV-only left exit ramp to Northside Drive for the southbound Interstate 75 HOV through lane." A contributing factor to the crash was "failure of the Georgia Department of Transportation to install adequate traffic control devices to identify the separation and divergence of the Northside Drive HOV-only left exit ramp from the southbound Interstate 75 HOV through lane." The NTSB further determined that contributing to the severity of the crash was "the motorcoach's lack of an adequate occupant protection system."},
	language = {en},
	urldate = {2018-07-08},
	journal = {Wikipedia},
	month = may,
	year = {2018},
	note = {Page Version ID: 843580777},
	file = {Snapshot:C\:\\Users\\Amir\\Zotero\\storage\\MX3AR4T9\\index.html:text/html}
}

@article{estelles-arolas_towards_2012,
	title = {Towards an {Integrated} {Crowdsourcing} {Definition}},
	volume = {38},
	issn = {0165-5515},
	url = {http://dx.doi.org/10.1177/0165551512437638},
	doi = {10.1177/0165551512437638},
	abstract = {'Crowdsourcing' is a relatively recent concept that encompasses many practices. This diversity leads to the blurring of the limits of crowdsourcing that may be identified virtually with any type of internet-based collaborative activity, such as co-creation or user innovation. Varying definitions of crowdsourcing exist, and therefore some authors present certain specific examples of crowdsourcing as paradigmatic, while others present the same examples as the opposite. In this article, existing definitions of crowdsourcing are analysed to extract common elements and to establish the basic characteristics of any crowdsourcing initiative. Based on these existing definitions, an exhaustive and consistent definition for crowdsourcing is presented and contrasted in 11 cases.},
	number = {2},
	urldate = {2018-07-09},
	journal = {J. Inf. Sci.},
	author = {Estellés-Arolas, Enrique and González-Ladrón-De-Guevara, Fernando},
	month = apr,
	year = {2012},
	keywords = {crowdsourcing, definition, innovation},
	pages = {189--200}
}

@book{mccall_factors_1977,
	title = {Factors in software quality},
	volume = {1,2,3},
	publisher = {General Electric},
	author = {McCall, Jim A and Richards, Paul K and Walters, Gene F},
	year = {1977}
}

@inproceedings{boehm_quantitative_1976,
	title = {Quantitative evaluation of software quality},
	booktitle = {Proceedings of the 2nd international conference on {Software} engineering},
	publisher = {IEEE Computer Society Press},
	author = {Boehm, Barry W and Brown, John R and Lipow, Mlity},
	year = {1976},
	pages = {592--605}
}

@article{radatz_ieee_1990,
	title = {{IEEE} standard glossary of software engineering terminology},
	volume = {610121990},
	number = {121990},
	journal = {IEEE Std},
	author = {Radatz, Jane and Geraci, Anne and Katki, Freny},
	year = {1990},
	pages = {3}
}

@article{shackel_usability-context_1991,
	title = {Usability-context, framework, definition, design and evaluation},
	journal = {Human factors for informatics usability},
	author = {Shackel, Brian},
	year = {1991},
	pages = {21--37}
}

@inproceedings{bevan_what_1991,
	title = {What is {Usability}?},
	booktitle = {Proceedings of the 4th international {Conference} on {HCI}},
	author = {Bevan, N and Kirakowski, J and Maissel, J},
	year = {1991}
}

@book{grady_practical_1992,
	address = {Upper Saddle River, NJ, USA},
	title = {Practical {Software} {Metrics} for {Project} {Management} and {Process} {Improvement}},
	isbn = {978-0-13-720384-0},
	publisher = {Prentice-Hall, Inc.},
	author = {Grady, Robert B.},
	year = {1992}
}

@book{nielsen_usability_1994,
	title = {Usability engineering},
	publisher = {Elsevier},
	author = {Nielsen, Jakob},
	year = {1994}
}

@article{iso/iec_iso/iec_1991,
	title = {{ISO}/{IEC} 9126: {Information} {Technology}—{Software} {Product} {Evaluation}—{Quality} {Characteristics} and {Guidelines} for their {Use}},
	author = {{ISO/IEC}},
	year = {1991}
}

@article{bertoa_quality_2002,
	title = {Quality attributes for {COTS} components},
	author = {Bertoa, Manuel F and Vallecillo, Antonio},
	year = {2002}
}

@article{georgiadou_gequamogeneric_2003,
	title = {{GEQUAMO}—a generic, multilayered, customisable, software quality model},
	volume = {11},
	number = {4},
	journal = {Software Quality Journal},
	author = {Georgiadou, Elli},
	year = {2003},
	pages = {313--323}
}

@article{abran_usability_2003,
	title = {Usability meanings and interpretations in {ISO} standards},
	volume = {11},
	number = {4},
	journal = {Software quality journal},
	author = {Abran, Alain and Khelifi, Adel and Suryn, Witold and Seffah, Ahmed},
	year = {2003},
	pages = {325--338}
}

@article{bass_linking_2003,
	title = {Linking usability to software architecture patterns through general scenarios},
	volume = {66},
	number = {3},
	journal = {Journal of Systems and Software},
	author = {Bass, Len and John, Bonnie E},
	year = {2003},
	pages = {187--197}
}

@book{shneiderman_designing_2016,
	edition = {6},
	title = {Designing the {User} {Interface}: {Strategies} for {Effective} {Human}-{Computer} {Interaction}},
	publisher = {Pearson},
	author = {Shneiderman, Ben and Plaisant, Catherine and Cohen, Maxine and Jacobs, Steven and Elmqvist, Niklas and Diakopoulos, Nicholas},
	year = {2016}
}

@book{shneiderman_designing_2004,
	edition = {4},
	title = {Designing the {User} {Interface}: {Strategies} for {Effective} {Human}-{Computer} {Interaction}},
	isbn = {978-0-321-19786-3},
	shorttitle = {Designing the {User} {Interface}},
	publisher = {Pearson Addison Wesley},
	author = {Shneiderman, Ben and Plaisant, Catherine},
	year = {2004}
}

@book{wagner_software_2013,
	address = {Berlin, Heidelberg},
	title = {Software {Product} {Quality} {Control}},
	isbn = {978-3-642-38570-4 978-3-642-38571-1},
	url = {http://link.springer.com/10.1007/978-3-642-38571-1},
	language = {en},
	urldate = {2018-07-11},
	publisher = {Springer Berlin Heidelberg},
	author = {Wagner, Stefan},
	year = {2013},
	doi = {10.1007/978-3-642-38571-1},
	file = {Software-Product-Quality-Control-1.pdf:C\:\\Users\\Amir\\Desktop\\My Desktop\\papers\\Software-Product-Quality-Control-1.pdf:application/pdf}
}

@article{wagner_software_2012,
	title = {Software {Quality} {Models} in {Practice} {Survey} {Results}},
	language = {en},
	journal = {Technical Report TUM-I128},
	author = {Wagner, Stefan and Lochmann, Klaus and Winter, Sebastian and Goeb, Andreas and Klaes, Michael and Nunnenmacher, Sabine},
	year = {2012},
	pages = {24},
	file = {1110601.pdf:C\:\\Users\\Amir\\Zotero\\storage\\KQ5GLPPL\\1110601.pdf:application/pdf}
}

@inproceedings{deissenboeck_software_2009,
	title = {Software quality models: {Purposes}, usage scenarios and requirements},
	booktitle = {Software {Quality}, 2009. {WOSQ}'09. {ICSE} {Workshop} on},
	publisher = {IEEE},
	author = {Deissenboeck, Florian and Juergens, Elmar and Lochmann, Klaus and Wagner, Stefan},
	year = {2009},
	pages = {9--14}
}

@article{dromey_model_1995,
	title = {A model for software product quality},
	volume = {21},
	number = {2},
	journal = {IEEE Transactions on software engineering},
	author = {Dromey, R. Geoff},
	year = {1995},
	pages = {146--162}
}

@book{lyu_handbook_1996,
	title = {Handbook of software reliability engineering},
	volume = {222},
	publisher = {IEEE computer society press CA},
	author = {Lyu, Michael R and {others}},
	year = {1996}
}

@book{musa_software_2004,
	title = {Software reliability engineering: more reliable software, faster and cheaper},
	publisher = {Tata McGraw-Hill Education},
	author = {Musa, John D},
	year = {2004}
}

@inproceedings{neuhaus_predicting_2007,
	title = {Predicting vulnerable software components},
	booktitle = {Proceedings of the 14th {ACM} conference on {Computer} and communications security},
	publisher = {ACM},
	author = {Neuhaus, Stephan and Zimmermann, Thomas and Holler, Christian and Zeller, Andreas},
	year = {2007},
	pages = {529--540}
}

@inproceedings{abrahamsson_mobile-d:_2004,
	title = {Mobile-{D}: an agile approach for mobile application development},
	isbn = {978-1-58113-833-7},
	shorttitle = {Mobile-{D}},
	url = {http://portal.acm.org/citation.cfm?doid=1028664.1028736},
	doi = {10.1145/1028664.1028736},
	abstract = {Mobile phones have been closed environments until recent years. The change brought by open platform technologies such as the Symbian operating system and Java technologies has opened up a significant business opportunity for anyone to develop application software such as games for mobile terminals. However, developing mobile applications is currently a challenging task due to the specific demands and technical constraints of mobile development. Furthermore, at the moment very little is known about the suitability of the different development processes for mobile application development. Due to these issues, we have developed an agile development approach called Mobile-D. The Mobile-D approach is briefly outlined here and the experiences gained from four case studies are discussed.},
	language = {en},
	urldate = {2018-07-24},
	publisher = {ACM Press},
	author = {Abrahamsson, Pekka and Hanhineva, Antti and Hulkko, Hanna and Ihme, Tuomas and J��linoja, Juho and Korkala, Mikko and Koskela, Juha and Kyll�nen, Pekka and Salo, Outi},
	year = {2004},
	pages = {174},
	file = {Abrahamsson et al. - 2004 - Mobile-D an agile approach for mobile application.pdf:C\:\\Users\\Amir\\Zotero\\storage\\GQUPK43X\\Abrahamsson et al. - 2004 - Mobile-D an agile approach for mobile application.pdf:application/pdf}
}

@article{al-qutaish_quality_2010,
	title = {Quality {Models} in {Software} {Engineering} {Literature}: {An} {Analytical} and {Comparative} {Study}},
	abstract = {The quality of the software is critical and essential in different types of organizations. In some types of software, poor quality of the software product in sensitive systems (such as: real-time systems, control systems, etc.) may lead to loss of human life, permanent injury, mission failure, or financial loss. In software engineering literature, there are a number of quality models in which they contain a number of quality characteristics (or factors, as called in some models). These quality characteristics could be used to reflect the quality of the software product from the view of that characteristic. Selecting which one of the quality models to use is a real challenge. In this paper, we will discuss the contents of the following quality models: McCall’s quality model, Boehm’s quality model, Dromey's quality model, FURPS quality model and ISO 9126 quality model. In addition, we will focus on a comparison between these quality models, and find the key differences between them. [Journal of American Science 2010; 6(3):166-175]. (ISSN: 1545-1003).},
	language = {en},
	author = {Al-Qutaish, Rafa E},
	year = {2010},
	pages = {10},
	file = {Al-Qutaish - Quality Models in Software Engineering Literature.pdf:C\:\\Users\\Amir\\Zotero\\storage\\LA4EYB88\\Al-Qutaish - Quality Models in Software Engineering Literature.pdf:application/pdf}
}

@article{rawashdeh_new_2006,
	title = {A {New} {Software} {Quality} {Model} for {Evaluating} {COTS} {Components}},
	volume = {2},
	issn = {15493636},
	url = {http://www.thescipub.com/abstract/?doi=jcssp.2006.373.381},
	doi = {10.3844/jcssp.2006.373.381},
	abstract = {Studies show that COTS-based (Commercial off the shelf) systems that are being built recently are exceeding 40\% of the total developed software systems. Therefore, a model that ensures quality characteristics of such systems becomes a necessity. Among the most critical processes in COTS-based systems are the evaluation and selection of the COTS components. There are several existing quality models used to evaluate software systems in general; however, none of them is dedicated to COTS-based systems. In this contribution, an analysis study has been carried out on several existing software quality models, namely: McCall’s, Boehm, ISO 9126, FURPS, Dromey, ISO/IEC TR 15504-2 1998(E), Triangle and Quality Cube, for the purpose of evaluating them and defining a ground to build a new model specializing in evaluating and selecting COTS components. The study also outlines limitations found in the existing models, such as the tendency to ignore a certain quality feature like Functionality or the failure to describe how the quality measurement in these models has been carried out. As a result of this analysis, a new model has been built that supports a standard set of quality characteristics suitable for evaluating COTS components, along with newly defined sets of sub-characteristics associated with them. The new model avoids some of the limitations found in the existing models. The new model ignores quality characteristics that are not applicable to COTS components and is empowered with new ones that are. In addition, it matches the appropriate type of stakeholders with corresponding quality characteristics; such a feature is missing in all existing models. The objective of the new model is to guide organizations that are in the process of building COTS-based systems to evaluate and choose the appropriate products, and that is essential to the success of the entire system.},
	language = {en},
	number = {4},
	urldate = {2018-07-24},
	journal = {Journal of Computer Science},
	author = {Rawashdeh, Adnan and Matalkah, Bassem},
	month = apr,
	year = {2006},
	pages = {373--381},
	file = {1b6114a409629e19862a5bc49c8557e578d8.pdf:C\:\\Users\\Amir\\Zotero\\storage\\2ZPLK957\\1b6114a409629e19862a5bc49c8557e578d8.pdf:application/pdf}
}

@article{wagner_quamoco_2012,
	title = {The {Quamoco} {Product} {Quality} {Modelling} and {Assessment} {Approach}},
	url = {http://arxiv.org/abs/1611.04433},
	doi = {10.1109/ICSE.2012.6227106},
	abstract = {Published software quality models either provide abstract quality attributes or concrete quality assessments. There are no models that seamlessly integrate both aspects. In the project Quamoco, we built a comprehensive approach with the aim to close this gap. For this, we developed in several iterations a meta quality model specifying general concepts, a quality base model covering the most important quality factors and a quality assessment approach. The meta model introduces the new concept of a product factor, which bridges the gap between concrete measurements and abstract quality aspects. Product factors have measures and instruments to operationalise quality by measurements from manual inspection and tool analysis. The base model uses the ISO 25010 quality attributes, which we refine by 200 factors and 600 measures for Java and C\# systems. We found in several empirical validations that the assessment results fit to the expectations of experts for the corresponding systems. The empirical analyses also showed that several of the correlations are statistically significant and that the maintainability part of the base model has the highest correlation, which fits to the fact that this part is the most comprehensive. Although we still see room for extending and improving the base model, it shows a high correspondence with expert opinions and hence is able to form the basis for repeatable and understandable quality assessments in practice.},
	urldate = {2018-07-24},
	journal = {arXiv:1611.04433 [cs]},
	author = {Wagner, Stefan and Lochmann, Klaus and Heinemann, Lars and Kläs, Michael and Trendowicz, Adam and Plösch, Reinhold and Seidl, Andreas and Goeb, Andreas and Streit, Jonathan},
	month = jun,
	year = {2012},
	note = {arXiv: 1611.04433},
	keywords = {Computer Science - Software Engineering},
	pages = {1133--1142},
	annote = {Comment: 10 pages, 2 figures, Proc. 34th International Conference on Software Engineering (ICSE'12). IEEE, 2012},
	file = {arXiv\:1611.04433 PDF:C\:\\Users\\Amir\\Zotero\\storage\\98YUYADF\\Wagner et al. - 2012 - The Quamoco Product Quality Modelling and Assessme.pdf:application/pdf;arXiv.org Snapshot:C\:\\Users\\Amir\\Zotero\\storage\\D6V2HMPT\\1611.html:text/html}
}

@inproceedings{samarthyam_midas:_2013,
	title = {{MIDAS}: {A} design quality assessment method for industrial software},
	isbn = {978-1-4673-3076-3 978-1-4673-3073-2},
	shorttitle = {{MIDAS}},
	url = {http://ieeexplore.ieee.org/document/6606640/},
	doi = {10.1109/ICSE.2013.6606640},
	abstract = {Siemens Corporate Development Center Asia Australia (CT DC AA) develops and maintains software applications for the Industry, Energy, Healthcare, and Infrastructure \& Cities sectors of Siemens. The critical nature of these applications necessitates a high level of software design quality. A survey of software architects indicated a low level of satisfaction with existing design assessment practices in CT DC AA and highlighted several shortcomings of existing practices. To address this, we have developed a design assessment method called MIDAS (Method for Intensive Design ASsessments). MIDAS is an expert-based method wherein manual assessment of design quality by experts is directed by the systematic application of design analysis tools through the use of a three view-model consisting of design principles, project-specific constraints, and an “ility”-based quality model. In this paper, we describe the motivation for MIDAS, its design, and its application to three projects in CT DC AA. We believe that the insights from our MIDAS experience not only provide useful pointers to other organizations and practitioners looking to assess and improve software design quality but also suggest research questions for the software engineering community to explore.},
	language = {en},
	urldate = {2018-07-24},
	publisher = {IEEE},
	author = {Samarthyam, Ganesh and Suryanarayana, Girish and Sharma, Tushar and Gupta, Shrinath},
	month = may,
	year = {2013},
	pages = {911--920},
	file = {MIDAS-A-Design-Quality-Assessment-Method-for-Industrial-Software.pdf:C\:\\Users\\Amir\\Zotero\\storage\\855H2Z42\\MIDAS-A-Design-Quality-Assessment-Method-for-Industrial-Software.pdf:application/pdf}
}

@misc{noauthor_iso_nodate,
	title = {{ISO} 25010},
	url = {http://iso25000.com/index.php/en/iso-25000-standards/iso-25010},
	urldate = {2018-07-26},
	file = {ISO 25010:C\:\\Users\\Amir\\Zotero\\storage\\EYWLQ8UG\\iso-25010.html:text/html}
}

@article{alvaro_quality_2005,
	title = {Quality {Attributes} for a {Component} {Quality} {Model}},
	abstract = {Component-based software development is becoming more generalized, representing a considerable market for the software industry. The perspective of reduced development costs and shorter life cycles acts as a motivation for this expansion. However, several technical issues remain unsolved before software component’s industry reaches the maturity exhibited by other component industries. Problems such as the component selection by their integrators, the component catalogs formalization and the uncertain quality of third-party developed components, bring new challenges to the software engineering community. By the other hand, the software components certification area is still immature and further research is needed in order to obtain well-defined standards for certification. In this way, we aim to propose a component quality model, describing mainly the quality attributes and related metrics for the components evaluation.},
	language = {en},
	author = {Alvaro, Alexandre},
	year = {2005},
	pages = {8},
	file = {10.1.1.93.4703.pdf:C\:\\Users\\Amir\\Desktop\\10.1.1.93.4703.pdf:application/pdf}
}

@article{alvaro_software_2010,
	title = {A {Software} {Component} {Quality} {Framework}},
	volume = {35},
	issn = {0163-5948},
	url = {http://doi.acm.org/10.1145/1668862.1668863},
	doi = {10.1145/1668862.1668863},
	abstract = {One of the major problems with Component-Based Software Engineering (CBSE) is the quality of the components used in a system. The reliability of a component-based software system depends on the reliability of the components that is made of. In CBSE, the proper search, selection and evaluation process of components is considered the cornerstone for the development of any effective component-based system. So far the software industry was concentrated on the functional aspects of components, leaving aside the difficult task of assessing their quality. In this way, we propose a software component quality framework to evaluate the quality of software components in an efficient way. Moreover, an experimental study was accomplished in order to evaluate the viability of the proposed framework.},
	number = {1},
	urldate = {2018-07-26},
	journal = {SIGSOFT Softw. Eng. Notes},
	author = {Alvaro, Alexandre and Santana de Almeida, Eduardo and Romero de Lemos Meira, Silvio},
	month = jan,
	year = {2010},
	pages = {1--18}
}

@article{alonso-rios_usability:_2009,
	title = {Usability: a critical analysis and a taxonomy},
	volume = {26},
	number = {1},
	journal = {International Journal of Human-Computer Interaction},
	author = {Alonso-Ríos, David and Vázquez-García, Ana and Mosqueira-Rey, Eduardo and Moret-Bonillo, Vicente},
	year = {2009},
	pages = {53--74}
}

@article{kumardubey_usability_2012,
	title = {Usability {Evaluation} of {Object} {Oriented} {Software} {System} using {Fuzzy} {Logic} {Approach}},
	volume = {43},
	issn = {09758887},
	url = {http://research.ijcaonline.org/volume43/number19/pxc3878778.pdf},
	doi = {10.5120/6208-8778},
	abstract = {The growth in demand for interactive software system has increased greatly in recent years. But, most of the developed systems are failing due to not providing suitable interface. User interface is the only way by which user can interact with software system. The problem lying in the interface is related to the usability. Usability is regarded as important quality factor for developing the successful interactive software system. It is also a key quality factor in the development of successful software applications. These days mostly software systems are developed using object-oriented methodology. Object-oriented approach enhances the usability of software system when software engineering process combined with usability engineering. Incorporating object-oriented concepts and techniques into system development processes, systems related to human computer interaction are more usable. Inspite of the importance of usability, there is no well defined criteria to evaluate it due the fact that many factors influence the usability of software system. This paper identifies the most important factors that impact on usability of objectoriented system and then proposes a model for evaluating the usability of software system using soft computing technique.},
	language = {en},
	number = {19},
	urldate = {2018-07-26},
	journal = {International Journal of Computer Applications},
	author = {KumarDubey, Sanjay and Rana, Ajay and Sharma, Arun},
	month = apr,
	year = {2012},
	pages = {1--6},
	file = {KumarDubey et al. - 2012 - Usability Evaluation of Object Oriented Software S.pdf:C\:\\Users\\Amir\\Desktop\\KumarDubey et al. - 2012 - Usability Evaluation of Object Oriented Software S.pdf:application/pdf}
}

@misc{noauthor_measuringu:_2018,
	title = {{MeasuringU}: {The} {User} {Experience} of {University} {Websites}},
	shorttitle = {{MeasuringU}},
	url = {https://measuringu.com/ux-university/},
	language = {en},
	urldate = {2018-07-26},
	month = jul,
	year = {2018}
}

@misc{noauthor_progressive_nodate,
	title = {Progressive {Web} {Apps}  {\textbar}  {Web}  {\textbar}  {Google} {Developers}},
	url = {https://developers.google.com/web/progressive-web-apps/},
	urldate = {2018-07-26},
	file = {Progressive Web Apps  |  Web  |  Google Developers:C\:\\Users\\Amir\\Zotero\\storage\\U5796NLC\\progressive-web-apps.html:text/html}
}

@inproceedings{hewett_role_1986,
	address = {New York, NY, USA},
	title = {The {Role} of {Iterative} {Evaluation} in {Designing} {Systems} for {Usability}},
	isbn = {0-521-33259-1},
	url = {http://dl.acm.org/citation.cfm?id=17324.24085},
	booktitle = {Proceedings of the {Second} {Conference} of the {British} {Computer} {Society}, {Human} {Computer} {Interaction} {Specialist} {Group} on {People} and {Computers}: {Designing} for {Usability}},
	publisher = {Cambridge University Press},
	author = {Hewett, T T},
	year = {1986},
	pages = {196--214}
}

@misc{noauthor_formative_nodate,
	title = {Formative and {Summative} {Evaluation}},
	url = {http://emilyburritt.weebly.com/formative-and-summative-evaluation.html},
	abstract = {Summative Evaluation: Is the process of evaluating students’ achievements and progress at the end of the course. Examples of Summative Evaluation: 1.Written Exams. 2.Final paper. 3. Final projects....},
	urldate = {2018-07-29},
	journal = {Emily Burritt's E-Portfolio}
}

@inproceedings{sauerwein_kano_1996,
	title = {The {Kano} model: {How} to delight your customers},
	volume = {1},
	booktitle = {International {Working} {Seminar} on {Production} {Economics}},
	author = {Sauerwein, Elmar and Bailom, Franz and Matzler, Kurt and Hinterhuber, Hans H},
	year = {1996},
	pages = {313--327}
}

@misc{noauthor_kano_2018,
	title = {Kano model},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Kano_model&oldid=847738497},
	abstract = {The Kano model is a theory for product development and customer satisfaction developed in the 1980s by Professor Noriaki Kano, which classifies customer preferences into five categories.},
	language = {en},
	urldate = {2018-07-30},
	journal = {Wikipedia},
	month = jun,
	year = {2018},
	note = {Page Version ID: 847738497},
	file = {Snapshot:C\:\\Users\\Amir\\Zotero\\storage\\SQ3ZX4ZU\\index.html:text/html}
}

@article{kano_attractive_1984,
	title = {Attractive quality and must-be quality},
	volume = {14},
	url = {https://ci.nii.ac.jp/naid/10025070768/en/},
	journal = {Hinshitsu (Quality, the Journal of Japanese Society for Quality Control)},
	author = {KANO, N.},
	year = {1984},
	pages = {39--48}
}